{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLW Practical 3 (extra)\n",
    "# Any architecture on COLOR\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "In this practical, we will apply a linear model to the COLOR data set. The COLOR data set comes as 18 different colour classes (red, green, gold, etc.) consisting of 9x9x3 RGB images. The data will be downloaded automatically in the first cell. Alternatively, the data can be downloaded [here](https://drive.google.com/open?id=1b2zwUWVVwdJkEAavMXv1D9wfjaG0Nf1W).\n",
    "\n",
    "The challenge is to build a classifier that can correctly classify each of the 18 different colour classes present in the test set. You are welcome to use any network architecture for this exercise. Use a confusion matrix to understand what the model is struggling to classify correctly. What is your best test set accuracy? What network architecture can you use to improve certain colours to get higher classification accuracy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "if not os.path.isfile('data.pk'):\n",
    "    os.system('curl -L \"https://docs.google.com/uc?export=download&id=1b2zwUWVVwdJkEAavMXv1D9wfjaG0Nf1W\" > data.pk')\n",
    "print(\"Data downloaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: (6200, 246)\n",
      "Validation: (2067, 246)\n",
      "Testing: (2067, 246)\n",
      "\n",
      "Unique labels: \n",
      "                0\n",
      "0           black\n",
      "1   black & white\n",
      "2            blue\n",
      "3           brown\n",
      "4          copper\n",
      "5            gold\n",
      "6           green\n",
      "7            grey\n",
      "8    multi-colour\n",
      "9         neutral\n",
      "10         orange\n",
      "11           pink\n",
      "12         purple\n",
      "13            red\n",
      "14      rose gold\n",
      "15         silver\n",
      "16          white\n",
      "17         yellow\n",
      "\n",
      "Training examples: 6200\n",
      "Input dimension (flatten): 243\n",
      "Number of classes: 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# open the training, validation and test set #\n",
    "##############################################\n",
    "\n",
    "with open('data.pk', 'rb') as handle:\n",
    "    data = pk.load(handle)\n",
    "\n",
    "print('\\nTraining: {}\\nValidation: {}\\nTesting: {}\\n\\nUnique labels: \\n{}'.format(data[0].shape, data[1].shape, data[2].shape, data[3]))\n",
    "\n",
    "col = len(data[0].columns.values) - 3\n",
    "\n",
    "# one-hot encode the output labels #\n",
    "train_x, train_y = data[0][list(range(col))].values, pd.get_dummies(data[0]['class_id'].values).as_matrix()\n",
    "val_x, val_y = data[1][list(range(col))].values, pd.get_dummies(data[1]['class_id'].values).as_matrix()\n",
    "test_x, test_y = data[2][list(range(col))].values, pd.get_dummies(data[2]['class_id'].values).as_matrix()\n",
    "\n",
    "train_examples, x_dim, n_classes = train_x.shape[0], train_x.shape[1], train_y.shape[1]\n",
    "\n",
    "print('\\nTraining examples: {}\\nInput dimension (flatten): {}\\nNumber of classes: {}\\n'.format(train_examples, x_dim, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# save the model #\n",
    "##################\n",
    "\n",
    "def save_model(session, model_name):\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), ['output_prediction'])\n",
    "    with gfile.FastGFile(model_name, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# mini-batch #\n",
    "##############\n",
    "\n",
    "def random_mini_batches(X, Y, train_examples, mini_batch_size=64):\n",
    "    np.random.seed(None)\n",
    "    m = train_examples\n",
    "    mini_batches = []\n",
    "\n",
    "    permutation = list(np.random.permutation(m))\n",
    "\n",
    "    shuffled_X = X[permutation, :]\n",
    "    shuffled_Y = Y[permutation, :]\n",
    "    num_complete_minibatches = int(np.floor(m / mini_batch_size))\n",
    "\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size) #\n",
    "    if m % mini_batch_size != 0:\n",
    "        a = m - (num_complete_minibatches * mini_batch_size)\n",
    "        mini_batch_X = shuffled_X[-a:]\n",
    "        mini_batch_Y = shuffled_Y[-a:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# linear model #\n",
    "################\n",
    "\n",
    "def linear_model(x_dim, n_classes, keep_nodes):\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    x = tf.placeholder(tf.float32, [None, x_dim], name='input')\n",
    "    W1 = tf.Variable(tf.random_normal([x_dim, n_classes], stddev=np.sqrt(1. / x_dim)), name='W1')\n",
    "    b1 = tf.Variable(tf.zeros([n_classes]), name='b1')\n",
    "    y = tf.add(tf.matmul(x, W1), b1)\n",
    "    y_ = tf.placeholder(tf.float32, [None, n_classes])\n",
    "    prediction = tf.nn.softmax(y, name='output_prediction')\n",
    "    return x, W1, b1, y, y_, prediction, keep_prob, keep_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5\n",
      "Mini-batch size: 100\n",
      "Number of mini-batches: 62\n",
      "\n",
      "------------------------------------------\n",
      "Epoch 0:\n",
      "Training loss: 57.160\n",
      "Validation loss: 57.070\n",
      "\n",
      "Training accuracy:   28.32% (Top 5: 70.34%)\n",
      "Validation accuracy: 27.82% (Top 5: 69.42%)\n",
      "------------------------------------------\n",
      "Epoch 1:\n",
      "Training loss: 22.296\n",
      "Validation loss: 22.508\n",
      "\n",
      "Training accuracy:   34.00% (Top 5: 74.69%)\n",
      "Validation accuracy: 30.67% (Top 5: 74.36%)\n",
      "------------------------------------------\n",
      "Epoch 2:\n",
      "Training loss: 18.969\n",
      "Validation loss: 19.430\n",
      "\n",
      "Training accuracy:   38.76% (Top 5: 82.63%)\n",
      "Validation accuracy: 37.11% (Top 5: 82.83%)\n",
      "------------------------------------------\n",
      "Epoch 3:\n",
      "Training loss: 17.806\n",
      "Validation loss: 18.256\n",
      "\n",
      "Training accuracy:   37.81% (Top 5: 81.40%)\n",
      "Validation accuracy: 36.48% (Top 5: 80.36%)\n",
      "------------------------------------------\n",
      "Epoch 4:\n",
      "Training loss: 16.406\n",
      "Validation loss: 16.992\n",
      "\n",
      "Training accuracy:   36.60% (Top 5: 78.29%)\n",
      "Validation accuracy: 35.51% (Top 5: 76.83%)\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n",
      "------------------------------------------\n",
      "\n",
      "Training time: 0:00:05.392531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# define training cycle #\n",
    "#########################\n",
    "\n",
    "seed = None\n",
    "epochs = 5\n",
    "minibatch_size = 100\n",
    "num_minibatches = int(np.ceil(train_examples / minibatch_size))\n",
    "\n",
    "print('Epochs: {}\\nMini-batch size: {}\\nNumber of mini-batches: {}\\n'.format(epochs, minibatch_size, num_minibatches))\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    x, W1, b1, y, y_, prediction, keep_prob, keep_nodes = linear_model(x_dim, n_classes, 1.0)\n",
    "\n",
    "    #############################\n",
    "    # define loss/cost function #\n",
    "    #############################\n",
    "\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "    learning_rate = 0.001\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)\n",
    "\n",
    "    ###########################\n",
    "    # define model evaluation #\n",
    "    ###########################\n",
    "\n",
    "    # returns the index with the largest value across axis of a tensor #\n",
    "    act_class, pred_class = tf.argmax(y_, 1), tf.argmax(tf.nn.softmax(y), 1)\n",
    "    correct_prediction = tf.cast(tf.equal(pred_class, act_class), tf.float32)\n",
    "    classification_accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    labels = tf.argmax(y_, 1)\n",
    "    top_five = tf.nn.in_top_k(tf.nn.softmax(y), labels, 5)\n",
    "    top_5_accuracy = tf.reduce_mean(tf.cast(top_five, tf.float32))\n",
    "\n",
    "    # launch the graph in a session (use the session as a context manager) #\n",
    "    with tf.Session() as sess:\n",
    "        # initializing the variables before starting the session #\n",
    "        init = tf.global_variables_initializer()\n",
    "        # run session #\n",
    "        sess.run(init)\n",
    "        loss = []\n",
    "        start_time = time.time()\n",
    "        # loop every epoch #\n",
    "        for epoch in range(epochs):\n",
    "            # average cost per epoch #\n",
    "            train_avg_cost = 0.\n",
    "            val_avg_cost = 0.\n",
    "            # get mini-batches #\n",
    "            minibatches = random_mini_batches(train_x, train_y, train_examples, minibatch_size)\n",
    "            total_batch = len(minibatches)\n",
    "            # loop every mini-batch #\n",
    "            for minibatch in minibatches:\n",
    "                # determine batch #\n",
    "                batch_xs, batch_ys = minibatch\n",
    "                # calculate validation loss #\n",
    "                train_cross_ent_loss = sess.run(cross_entropy_loss, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "                # calculate validation loss #\n",
    "                val_cross_ent_loss = sess.run(cross_entropy_loss, feed_dict={x: val_x, y_: val_y, keep_prob: 1.0})\n",
    "                # execute operations on graph #\n",
    "                sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: keep_nodes})\n",
    "                # average cost per number of mini-batches #\n",
    "                train_avg_cost += train_cross_ent_loss / total_batch\n",
    "                val_avg_cost += val_cross_ent_loss / total_batch\n",
    "                # training and validation accuracy #\n",
    "                train_class_acc, train_top_5_acc = sess.run([classification_accuracy, top_5_accuracy], feed_dict={x: train_x, y_: train_y, keep_prob: 1.0})\n",
    "                val_class_acc, val_top_5_acc = sess.run([classification_accuracy, top_5_accuracy], feed_dict={x: val_x, y_: val_y, keep_prob: 1.0})\n",
    "\n",
    "            print('------------------------------------------')\n",
    "            print('Epoch {0}:\\nTraining loss: {1:.3f}\\nValidation loss: {2:.3f}\\n'.format(epoch, train_avg_cost, val_avg_cost))\n",
    "            print('Training accuracy:   {0:.2f}% (Top 5: {1:.2f}%)\\nValidation accuracy: {2:.2f}% (Top 5: {3:.2f}%)'.format(train_class_acc * 100, train_top_5_acc * 100, val_class_acc * 100, val_top_5_acc * 100))\n",
    "                \n",
    "        save_model(sess, 'output_graph.pb')\n",
    "\n",
    "    print('------------------------------------------')\n",
    "    print('\\nTraining time: {}\\n'.format(datetime.timedelta(seconds=time.time() - start_time)))\n",
    "    data[3]['colour_id'] = data[3].index.values\n",
    "\n",
    "    ###############################\n",
    "    # test and evaluate the model #\n",
    "    ###############################\n",
    "\n",
    "    # plot_losses(loss, show=True)\n",
    "    # p_class, a_class, c_acc, t_5 = sess.run([pred_class, act_class, classification_accuracy, top_5_accuracy], feed_dict={x: list(test_x), y_: test_y, keep_prob: 1.0})\n",
    "    # classify_report(a_class, p_class, data[3][0].values)\n",
    "    # print('\\nClassification accuracy: {0:.2f} (Top 3: {1:.2f})\\n'.format(c_acc, t_5))\n",
    "    # print('\\n', classification_report(a_class, p_class, target_names=data[3][0].values))\n",
    "    # confusion_matrix_plot(a_class, p_class, data[3][0].values, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
