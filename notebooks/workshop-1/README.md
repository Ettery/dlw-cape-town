# Workshop 1

## From linear to non-linear models

### Objective

In this workshop, our objective is to implement a linear classifier on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. Then we will add one hidden layer to create a non-linear (more complex) decision boundary. We this this in an effort to improve the model's classification accuracy, since the classes are not linearly separable.

The MNIST dataset contains binary images of handwritten digits and is used throughout the machine learning community to varify and test the performance of machine learning algorithms. This dataset is also easy to use with ```Tensorflow``` as it comes with pre-build helper functions to access the training data, which is useful during the training procedure.

After you have tested the linear classifier, your job is to add a hidden layer to your model. Then play with the hyperparameters until you get good results. Compare your results to that of your simpler linear model at make sure you understand what the hidden layer contributed to your model.

The MNIST dataset will be downloaded automatically within the notebook.

